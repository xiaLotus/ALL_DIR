import glob
import os
import re
from flask import Flask, jsonify
from flask_cors import CORS
import pandas as pd
from waitress import serve

app = Flask(__name__)
CORS(app)  # å…è¨±å‰ç«¯è«‹æ±‚
# FILE_PATH = "//20220530-W03/Data/å ±æ¡ˆç³»çµ±è³‡æ–™ç®¡æ§"
FILE_PATH = os.getcwd()
print(f"ğŸ“‚ ç•¶å‰ç¨‹å¼è³‡æ–™å¤¾: {FILE_PATH}")

@app.route('/api/week_num')
def get_week_num():
    folder = f'{FILE_PATH}/æ¯æ—¥éå¸³ç›¸é—œçµ±è¨ˆ'
    # print(f"ğŸ” æƒæè³‡æ–™å¤¾ï¼š{folder}")

    # æ‰¾å‡ºæ‰€æœ‰ CSV æª”æ¡ˆ
    files = glob.glob(f"{folder}/*.csv")
    # print("ğŸ“‚ æ‰¾åˆ°çš„æª”æ¡ˆï¼š", files)

    week_tags = []
    for f in files:
        filename = os.path.basename(f) 
        match = re.search(r'(\d{4})-W(\d{1,2})', filename)
        if match:
            year = match.group(1)
            week = int(match.group(2))
            week_tags.append(f"{year}-W{week:02d}") 

    # print("ğŸ“… æ“·å–åˆ°çš„é€±åˆ¥ï¼š", week_tags)

    if week_tags:
        latest_week = max(week_tags, key=lambda x: int(x[:4]) * 100 + int(x[6:]))
        return jsonify({"latest_week": latest_week})

    return jsonify({"latest_week": None})


@app.route('/api/factory-data')
def get_factory_data():
    # å…¨éƒ¨æ¬„ä½è®€å–ç‚º string
    df = pd.read_csv(f'{FILE_PATH}/å„é€±è³‡æ–™.csv', encoding='utf-8-sig', dtype=str)

    # åƒ…å–æœ€å¾Œä¸‰ç­†
    last_rows = df.tail(3)

    # å·¥å…·å‡½å¼ï¼šè§£æ () å…§æ•¸å­—ä¸¦åŠ ç¸½
    def parse_and_sum(value):
        if pd.isna(value) or str(value).strip() == "0":
            return 0
        matches = re.findall(r"\((\d+)\)", str(value))
        return sum(int(m) for m in matches)

    # éœ€è¦çµ±è¨ˆçš„æ¬„ä½
    target_cols = ["2Dæ¶ˆé™¤", "EAPé‡é–‹", "éå¸³ç•°å¸¸", "é—œé–‰æ¯”å°", "å…¶ä»–äº‹é …", "æ›´æ–°/æ¬é·"]

    # è¨ˆç®— summaryï¼ˆåªé‡å°æœ€å¾Œä¸‰ç­†ï¼‰
    summary = {}


    for col in target_cols:
        total_val = last_rows[col].apply(parse_and_sum).sum()
        summary[f"{col}çµ±è¨ˆ"] = int(total_val)

    # ç¸½è¨ˆçµ±è¨ˆ = å…­å€‹åˆä½µ
    summary["ç¸½è¨ˆçµ±è¨ˆ"] = sum(summary.values())

    # è½‰ç‚º list of dict å‚³å‡º JSON
    data = {
        "records": last_rows.to_dict(orient="records"),
        "summary": summary
    }
    return jsonify(data)


@app.route('/api/posting-counts')
def get_posting_counts():

    folder = f'{FILE_PATH}/æ¯æ—¥éå¸³ç›¸é—œçµ±è¨ˆ'
    # folder = f'æ¯æ—¥éå¸³ç›¸é—œçµ±è¨ˆ'
    # æ‰¾å‡ºæ‰€æœ‰ç¬¦åˆæ ¼å¼çš„æª”åï¼ˆä¾‹å¦‚ï¼š2025-W14-æ¯æ—¥éå¸³ç›¸é—œçµ±è¨ˆ.csvï¼‰
    files = glob.glob(f"{folder}/*.csv")

    # å¾æª”åä¸­æå–é€±æ¬¡ä¸¦æ’åºï¼Œæ ¼å¼ç‚º 2025-W14
    def extract_week_key(filepath):
        match = re.search(r'(\d{4})-W(\d+)', filepath)
        if match:
            year, week = match.groups()
            return int(year) * 100 + int(week)  # ä¾‹å¦‚ 202514
        return 0

    # å–å¾—é€±æ¬¡æœ€å¤§çš„æª”æ¡ˆ

    latest_file = max(files, key=extract_week_key)
    df = pd.read_csv(latest_file, encoding='utf-8-sig')
    df = df.rename(columns={"æ—¥æœŸ": "date", "éå¸³ç›¸é—œä»¶æ•¸": "count"})
    df["count"] = df["count"].astype(int)
    return jsonify(df.to_dict(orient='records'))


@app.route('/api/weekly-summary')
def get_weekly_summary():

    # df = pd.read_csv(f'{FILE_PATH}/æ¯é€±åˆ†é¡çµ±è¨ˆ.csv', encoding='utf-8-sig')
    df = pd.read_csv(f'æ¯é€±åˆ†é¡çµ±è¨ˆ.csv', encoding='utf-8-sig')

    # æ•¸å€¼æ¬„ä½è½‰æˆ int
    df[["éå¸³ç•°å¸¸", "2Dæ¶ˆé™¤", "æ›´æ–°/æ¬é·", "ç¸½è¨ˆ"]] = df[["éå¸³ç•°å¸¸", "2Dæ¶ˆé™¤", "æ›´æ–°/æ¬é·", "ç¸½è¨ˆ"]].fillna(0).astype(int)

    # è½‰æˆ list[dict]
    last_two_rows = df.tail(8)
    data = last_two_rows.to_dict(orient='records')
    return jsonify(data)


@app.route('/api/oper-stats')
def get_oper_stats():
    import os
    import glob
    import re
    import pandas as pd

    folder = 'åˆ†é¡_Oper_No_Top3'
    files = glob.glob(f"{folder}/*.csv")

    if not files:
        print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½• {folder}/*.csv æª”æ¡ˆ")
        return jsonify({"error": f"æ‰¾ä¸åˆ°ä»»ä½• {folder}/*.csv æª”æ¡ˆ"}), 404

    def extract_week_key(filepath):
        match = re.search(r'(\d{4})-W(\d+)', filepath)
        if match:
            year, week = match.groups()
            return int(year) * 100 + int(week)
        return 0

    latest_file = max(files, key=extract_week_key)

    if not os.path.exists(latest_file):
        return jsonify({"error": f"æª”æ¡ˆä¸å­˜åœ¨ï¼š{latest_file}"}), 404

    df = pd.read_csv(latest_file, encoding='utf-8-sig')
    records = df.to_dict(orient='records')
    # ğŸ”¢ å»ºç«‹ summary çµ±è¨ˆ
    summary = []
    grouped = df.groupby(['Week', 'åˆ†é¡'])

    for (week, category), group in grouped:
        total = 0
        for count_str in group['æ¬¡æ•¸']:
            # ç¯„ä¾‹æ ¼å¼ï¼š'K11(12)/K25(3)'ï¼Œæå–æ‹¬è™Ÿå…§æ•¸å­—
            numbers = re.findall(r'\((\d+)\)', str(count_str))
            total += sum(int(n) for n in numbers)
        summary.append({
            'åˆ†é¡': category,
            'ç¸½æ¬¡æ•¸': total
        })
    # print(summary)
    return jsonify({
        "records": records,
        "summary": summary
    })



@app.route('/api/detailed-logs')
def get_detailed_logs():
    folder = f'{FILE_PATH}/å ±æ¡ˆè³‡æ–™è¡¨'

    # æ‰¾å‡ºæ‰€æœ‰ç¬¦åˆæ ¼å¼çš„æª”åï¼ˆä¾‹å¦‚ï¼š2025-W14-æ¯æ—¥éå¸³ç›¸é—œçµ±è¨ˆ.csvï¼‰
    files = glob.glob(f"{folder}/*.csv")

    # å¾æª”åä¸­æå–é€±æ¬¡ä¸¦æ’åºï¼Œæ ¼å¼ç‚º 2025-W14
    def extract_week_key(filepath):
        match = re.search(r'(\d{4})-W(\d+)', filepath)
        if match:
            year, week = match.groups()
            return int(year) * 100 + int(week)  # ä¾‹å¦‚ 202514
        return 0

    # å–å¾—é€±æ¬¡æœ€å¤§çš„æª”æ¡ˆ

    latest_file = max(files, key=extract_week_key)
    # latest_file = "2025-W36-å ±æ¡ˆè³‡æ–™è¡¨.csv"
    df = pd.read_csv(latest_file, encoding='utf-8-sig')

    # é¿å…ç©ºç™½æ¬„ä½ç‚º NaNï¼Œæ”¹æˆç©ºå­—ä¸²
    df = df.fillna("")

    # # ç¢ºä¿ Oper_No æ˜¯æ•´æ•¸ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
    # if "ç«™é»" in df.columns:
    #     df["ç«™é»"] = pd.to_numeric(df["ç«™é»"], errors="coerce").fillna(0).astype(int)

    data = df.to_dict(orient='records')
    return jsonify(data)

if __name__ == '__main__':
    app.run(debug=True)
    # serve(app, host='0.0.0.0', port=8097, threads=8)
    # app.run(debug=True)